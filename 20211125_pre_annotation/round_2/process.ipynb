{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "經過第一輪嘅標註同處理之後，我哋要做下面步驟：\n",
        "\n",
        "1. （完成）將下面兩個文件全部擺落`hand_extracted.csv`\n",
        "  1. `output/jyutping_useful.csv`\n",
        "  1. `re_output/jyutping_useful.csv`\n",
        "1. （完成）將 `re_output/no_jyutping_useful.csv` 加粵拼並揾人人工檢查之後加入 `hand_extracted.csv`\n",
        "1. （完成） `error_words.csv` 放入 `fixed.csv`檢查修正後加入總表\n",
        "1. （完成）將所有 `jyutping_junk.csv` 嘅詞，人手篩選有用嘅加入總表\n",
        "1. （完成）將`round_1_annotated/re_output/no_jyutping_junk.csv`入面嘅詞條人工篩選有用嘅放落 `hand_extracted.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 將`hand_extracted.csv` 嘅詞修正常見錯別字同語氣詞用字，同埋官話詞「吃」\n",
        "\n",
        "\n",
        "# 第二輪整理\n",
        "\n",
        "跟住將總表入面嘅所有詞彙進行下面嘅處理工作：\n",
        "\n",
        "1. （暫擱）整理出所有同音詞，然後討論規範寫法，刪除唔標準嘅寫法\n",
        "1. 將所有詞條轉成 OpenCC 字形，去重排序\n",
        "\n",
        "跟住就**發佈初版**，然後開始下一輪嘅人工處理：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Release\n",
        "import pandas as pd\n",
        "import opencc\n",
        "converter = opencc.OpenCC('hk2t.json')\n",
        "\n",
        "extracted = pd.read_csv('./hand_extracted.csv')\n",
        "hbl= pd.read_csv('./hbl_filtered.csv')\n",
        "wordshk = pd.read_csv('./wordshk_filtered.csv')\n",
        "data = pd.concat([extracted, hbl, wordshk], ignore_index=True)\n",
        "\n",
        "\n",
        "data['word'] = data['word'].apply(converter.convert)\n",
        "data.drop_duplicates(inplace=True)\n",
        "data.sort_values(by=['jyutping', 'word'], inplace=True)\n",
        "\n",
        "data.to_csv(\"released.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "common_char = r'(佢|我|你|唔|啊|啦|喇|㗎|咗|係|喺|嘅|嘢|乜|咁|冇|噉|咩|啲|諗|仲)'\n",
        "condition = data['word'].str.contains(common_char)\n",
        "phrase = data[condition]\n",
        "remain = data[~condition]\n",
        "phrase.to_csv('./release_phrase.csv', index=False)\n",
        "\n",
        "long = remain[remain['word'].str.len() > 4]\n",
        "remain = remain[remain['word'].str.len() <= 4]\n",
        "long.to_csv('./release_long.csv', index=False)\n",
        "\n",
        "multigraph = {}\n",
        "for i, row in data.iterrows():\n",
        "    if row['jyutping'] not in multigraph:\n",
        "        multigraph[row['jyutping']] = []\n",
        "    multigraph[row['jyutping']].append(row['word'])\n",
        "\n",
        "multi_list = []\n",
        "for jyutping, words in multigraph.items():\n",
        "    if len(words) > 1:\n",
        "        multi_list.append([jyutping, words])\n",
        "pd.DataFrame(multi_list).to_csv('homophone.csv', index=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
